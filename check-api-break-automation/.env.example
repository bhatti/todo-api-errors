# Google Cloud Configuration
GCP_PROJECT=your-gcp-project-id
GCP_REGION=us-central1

# Vertex AI Model Configuration
# Available models:
# - gemini-2.5-flash (fast, general purpose)
# - gemini-2.5-pro (advanced reasoning)
# - code-gemini-2.5-flash (optimized for code)
VERTEX_AI_MODEL=gemini-2.5-pro

# Optional: Service Account Key Path
# If not using default credentials
# GOOGLE_APPLICATION_CREDENTIALS=/path/to/service-account-key.json

# Buf Tool Configuration
BUF_TOKEN=your-buf-token-if-using-remote-registry

# MCP Server Configuration
MCP_SERVER_PORT=8080
MCP_SERVER_HOST=localhost

# Logging Configuration
LOG_LEVEL=INFO
LOG_FORMAT=json

# CI/CD Configuration
CI_MODE=false
FAIL_ON_BREAKING_CHANGES=true

# Output Configuration
OUTPUT_FORMAT=json
OUTPUT_DIR=./reports

# Cache Configuration
ENABLE_CACHE=true
CACHE_DIR=./.cache

# Analysis Configuration
# Comparison reference (git ref, tag, or branch)
COMPARISON_REFERENCE=HEAD~1

# Workspace Configuration
WORKSPACE_PATH=.

# Feature Flags
ENABLE_SEMANTIC_ANALYSIS=true
ENABLE_MCP_SERVER=false
ENABLE_PARALLEL_PROCESSING=true

# Rate Limiting (for API calls)
VERTEX_AI_REQUESTS_PER_MINUTE=60
VERTEX_AI_MAX_RETRIES=3

# Notification Configuration (optional)
# SLACK_WEBHOOK_URL=https://hooks.slack.com/services/...
# EMAIL_NOTIFICATIONS=false
# EMAIL_TO=team@example.com